Search.setIndex({"docnames": ["components/attentions", "components/feedforward", "components/index", "components/mha", "components/ops", "components/position_embedding", "components/reversible", "custom_parts/index", "index", "tutorials/blocksparse", "tutorials/extend_attentions", "tutorials/index", "tutorials/reversible", "tutorials/sparse_vit", "tutorials/triton", "tutorials/use_attention", "what_is_xformers"], "filenames": ["components/attentions.rst", "components/feedforward.rst", "components/index.rst", "components/mha.rst", "components/ops.rst", "components/position_embedding.rst", "components/reversible.rst", "custom_parts/index.rst", "index.rst", "tutorials/blocksparse.rst", "tutorials/extend_attentions.rst", "tutorials/index.rst", "tutorials/reversible.rst", "tutorials/sparse_vit.rst", "tutorials/triton.rst", "tutorials/use_attention.rst", "what_is_xformers.rst"], "titles": ["Attention mechanisms", "Feedforward mechanisms", "API Reference", "Multi Head Attention", "xFormers optimized operators", "Position Embeddings", "Reversible layer", "Custom parts reference", "Welcome to xFormers\u2019s documentation!", "Using BlockSparseAttention", "Extend the xFormers parts zoo", "Tutorials", "Using the Reversible block", "Replace all attentions from an existing ViT model with a sparse equivalent?", "Using Triton-based layers", "I\u2019m only interested in testing out the attention mechanisms that are hosted here", "What is xFormers?"], "terms": {"xformer": [2, 7, 9, 11, 12, 13, 14, 15], "optim": [2, 8, 14, 16], "oper": [2, 8, 14], "memori": [2, 9, 12], "effici": [2, 12], "attent": [2, 7, 8, 9, 10, 11, 12], "mechan": [2, 8, 10, 11, 13], "feedforward": [2, 8, 12], "posit": [2, 4, 8], "embed": [2, 8], "revers": [2, 8, 11], "layer": [2, 8, 11, 12], "multi": [2, 8, 12, 15], "head": [2, 8, 9, 12, 15], "class": [4, 10, 12], "op": 4, "fmha": 4, "ck": [4, 10], "fwop": 4, "sourc": [4, 7, 13, 16], "mha": [4, 12], "kernel": [4, 8, 14], "base": [4, 7, 8, 10, 11, 13, 15], "compos": [4, 16], "bwop": 4, "ck_decod": 4, "an": [4, 8, 9, 11, 14, 15], "k": [4, 10], "256": 4, "so": [4, 9, 10, 14, 16], "contigu": 4, "dim": [4, 12, 13], "fit": 4, "regist": [4, 10], "test": [4, 8, 10, 11, 16], "work": [4, 10, 13, 15], "mi250x": 4, "thi": [4, 9, 10, 12, 13, 14, 15, 16], "file": [4, 15], "contain": 4, "can": [4, 7, 8, 9, 10, 12, 13, 14, 15, 16], "us": [4, 7, 8, 10, 11, 13, 15], "attn_bia": 4, "argument": [4, 10], "memory_efficient_attent": 4, "essenti": 4, "bia": 4, "tensor": [4, 10, 12, 13, 14], "which": [4, 7, 8, 9, 10, 12, 13, 14, 15, 16], "ad": [4, 14], "q": [4, 10], "t": 4, "befor": 4, "comput": [4, 7, 9, 12], "softmax": 4, "The": [4, 7, 9, 10, 12, 13, 14, 15], "goal": [4, 14], "have": [4, 9, 13], "custom": 4, "made": [4, 12], "instead": 4, "dens": [4, 9], "we": [4, 7, 9, 10, 12, 13, 15], "want": [4, 7, 10, 13], "avoid": 4, "load": [4, 7], "from": [4, 7, 8, 9, 10, 11, 12, 14, 15], "perform": [4, 14], "reason": 4, "also": [4, 7, 10, 12, 14, 16], "abl": [4, 7], "know": 4, "hand": 4, "part": [4, 11], "matrix": [4, 9], "need": [4, 7, 9, 10, 12], "eg": 4, "causal": [4, 9, 10], "mask": [4, 7, 9, 13, 15], "some": [4, 7, 9, 12, 13, 14, 15], "veri": [4, 12, 14, 15], "common": [4, 7], "ar": [4, 7, 8, 10, 11, 12, 13, 14, 16], "lowertriangularmask": 4, "blockdiagonalmask": 4, "attentionbia": 4, "object": 4, "appli": [4, 10, 12], "That": [4, 15], "function": [4, 9, 12, 13], "ha": 4, "abil": 4, "add": 4, "qk": 4, "calcul": 4, "shape": [4, 13], "b": [4, 12], "1": [4, 9, 12, 13, 14, 15], "n_queri": 4, "number": [4, 12, 14], "kei": [4, 9], "given": [4, 10, 13, 15, 16], "input": [4, 12, 15], "most": 4, "case": [4, 13, 14, 15], "onli": [4, 7, 8, 11, 14], "zero": 4, "neg": 4, "infin": 4, "form": 4, "queri": [4, 9], "attend": 4, "children": 4, "defin": [4, 9, 10, 12, 13, 16], "altern": [4, 13, 15], "thing": [4, 10], "when": [4, 7, 12, 13, 14], "torch": [4, 9, 10, 12, 13, 14, 15], "doe": [4, 12], "materi": 4, "hardcod": 4, "better": [4, 9, 14], "see": [4, 7, 12], "lowertriangularfrombottomrightmask": 4, "lowertriangularmaskwithtensorbia": 4, "blockdiagonalcausalmask": 4, "tupl": 4, "int": [4, 10, 12], "dtype": [4, 9], "float32": 4, "devic": [4, 9, 15], "union": [4, 12], "str": 4, "cpu": 4, "slow": [4, 7], "don": 4, "attempt": 4, "make": [4, 9, 12, 14, 15], "fast": [4, 9, 16], "debug": 4, "should": [4, 12, 15], "like": [4, 10, 12, 13, 14, 15], "q_seqlen": 4, "k_seqlen": 4, "localattentionfrombottomrightmask": 4, "window_left": 4, "window_right": 4, "A": [4, 7, 9, 12], "local": [4, 10, 14, 16], "window": 4, "_left": 4, "s": [4, 9, 10, 13, 14, 15], "_right": 4, "With": 4, "num": 4, "_queri": 4, "_kei": 4, "exampl": [4, 7, 9, 13, 14], "import": [4, 9, 13, 14, 15], "2": [4, 9, 12], "print": [4, 9], "4": 4, "exp": 4, "5": 4, "4x4": 4, "0": [4, 7, 9, 15], "4x5": 4, "illustr": 4, "total": 4, "size": [4, 9], "exactli": [4, 12], "same": [4, 10, 12], "differ": [4, 9, 10, 12], "triangular": [4, 9], "shift": 4, "last": [4, 14], "In": [4, 13, 14, 15], "other": [4, 10, 12, 13, 14, 16], "word": 4, "cannot": [4, 16], "nearer": 4, "final": 4, "than": [4, 7, 9, 12, 14], "between": [4, 9, 12], "left": 4, "right": 4, "thei": [4, 7, 8], "becom": [4, 12, 15], "equival": [4, 8, 11], "equal": 4, "make_local_attent": 4, "window_s": 4, "lowertriangularfrombottomrightlocalattentionmask": 4, "creat": [4, 7, 8], "new": [4, 10, 15, 16], "combin": [4, 8, 12, 15], "_window_s": 4, "both": [4, 10], "whose": 4, "distanc": 4, "x": [4, 7, 10, 12, 14, 15], "either": [4, 14, 15], "less": [4, 7, 12], "i": [4, 8, 11], "e": [4, 7], "greater": 4, "green": 4, "area": 4, "grei": 4, "out": [4, 8, 9, 11], "q_seqinfo": 4, "_seqleninfo": 4, "k_seqinfo": 4, "_batch_siz": 4, "option": [4, 8, 10, 12], "sequenc": [4, 9, 12, 14, 15], "none": [4, 10, 14], "block": [4, 7, 8, 9, 10, 11, 16], "diagon": 4, "pass": [4, 9, 12], "each": [4, 14, 16], "divid": 4, "handl": 4, "batch": [4, 9, 10, 15], "length": [4, 9], "via": [4, 12], "from_tensor_list": 4, "16": [4, 9, 13, 15], "float16": [4, 9], "cuda": [4, 8, 9, 13, 14], "list_x": 4, "randn": [4, 9], "3": [4, 7, 12, 13, 15], "6": [4, 7, 9, 10], "linear": 4, "nn": [4, 9, 10, 12, 13, 14], "v": [4, 10], "reshap": 4, "unbind": 4, "list_out": 4, "split": 4, "assert": 4, "classmethod": 4, "from_seqlen": 4, "kv_seqlen": 4, "list": 4, "valu": [4, 7, 9, 16], "paramet": [4, 13, 15], "default": [4, 7, 10], "return": [4, 13], "concaten": 4, "dimens": [4, 9, 14, 15], "back": 4, "vari": 4, "m_i": 4, "all": [4, 8, 10, 11, 12, 14, 15, 16], "m": [4, 8, 11, 12], "correspond": [4, 14], "along": [4, 9, 14], "sum_i": 4, "invers": 4, "token": 4, "possibl": [4, 9, 14, 15], "make_caus": 4, "make_causal_from_bottomright": 4, "blockdiagonalcausalfrombottomrightmask": 4, "prefix": 4, "blockdiagonalcausallocalattentionmask": 4, "experiment": 4, "make_local_attention_from_bottomright": 4, "blockdiagonalcausallocalattentionfrombottomrightmask": 4, "start": [4, 9, 14], "bottom": 4, "except": 4, "nor": 4, "one": [4, 9, 10, 12, 13, 16], "farther": 4, "initi": [4, 15], "allow": [4, 15, 16], "note": [4, 9, 12, 13], "num_kei": 4, "num_queri": 4, "otherwis": 4, "forward": [4, 9, 10, 12], "vector": 4, "inf": 4, "blockdiagonalpaddedkeysmask": 4, "_paddedseqleninfo": 4, "support": [4, 7, 13, 14], "pad": 4, "For": 4, "space": 4, "12": 4, "three": [4, 10], "max": 4, "first": [4, 12], "kv_pad": 4, "without": [4, 12], "causal_diagon": 4, "ani": [4, 7, 10, 13, 14, 16], "upperbound": 4, "individu": 4, "unus": 4, "bc": 4, "blockdiagonalcausalwithoffsetpaddedkeysmask": 4, "offset": 4, "pagedblockdiagonalpaddedkeysmask": 4, "block_tabl": 4, "page_s": 4, "page": 4, "batch_siz": 4, "max_num_pag": 4, "num_head": [4, 9, 10, 13, 15], "head_dim": 4, "num_group": 4, "pagedblockdiagonalcausalwithoffsetpaddedkeysmask": 4, "blockdiagonalgappykeysmask": 4, "_gappyseqinfo": 4, "gappi": 4, "kv_seqstart": 4, "make_pag": 4, "notional_pad": 4, "paged_typ": 4, "type": [4, 10], "pagedblockdiagonalgappykeysmask": 4, "assum": 4, "our": [4, 9, 13], "actual": [4, 9, 14], "live": 4, "separ": 4, "convert": [4, 9], "version": [4, 7], "blockdiagonalcausalwithoffsetgappykeysmask": 4, "unlik": 4, "address": 4, "element": 4, "you": [4, 7, 9, 10, 12, 13, 14, 15, 16], "were": 4, "do": [4, 7, 10, 13, 15], "two": [4, 9, 12, 14, 15], "100": 4, "chang": [4, 7, 9], "ignor": 4, "would": [4, 10, 13, 15], "101": 4, "200": 4, "But": 4, "provid": [4, 7, 9, 14, 15], "featur": 4, "pattern": [4, 9, 13], "band": 4, "its": 4, "further": 4, "_subtensor": 4, "attentionbiassubtensor": 4, "lower": [4, 9], "aka": 4, "add_bia": 4, "arbitrari": 4, "addit": 4, "transpar": 7, "implement": [7, 12], "sputnik": 7, "These": [7, 14], "instal": 7, "recipi": 7, "machin": 7, "compil": [7, 14], "code": [7, 10, 14, 15], "git": 7, "clone": 7, "github": 7, "com": 7, "fairintern": 7, "conda": 7, "name": [7, 10, 13, 15], "xformer_env": 7, "python": [7, 14], "8": [7, 9, 13], "activ": [7, 12], "cd": 7, "pip": 7, "r": [7, 12], "txt": 7, "issu": 7, "relat": [7, 12], "nvcc": 7, "current": [7, 14], "runtim": 7, "match": [7, 9], "often": 7, "modul": [7, 10, 12, 13], "unload": 7, "xx": 7, "gcc": 7, "re": [7, 13, 15], "capabl": [7, 14], "torch_cuda_arch_list": 7, "env": 7, "variabl": 7, "set": [7, 12], "architur": 7, "suggest": 7, "setup": 7, "comprehens": 7, "export": 7, "7": 7, "automat": [7, 10, 16], "trigger": [7, 10], "scale": 7, "dot": 7, "product": 7, "enough": [7, 9], "30": 7, "true": [7, 9, 10, 12, 14], "There": [7, 10, 14, 15], "noth": 7, "specif": [7, 16], "coupl": [7, 10, 14], "tutori": [7, 14], "follow": [7, 10, 12, 13, 14, 16], "visibl": 7, "enabl": [7, 10, 14], "condit": 7, "met": 7, "warn": 7, "independ": 7, "model": [7, 8, 11, 12, 15, 16], "abov": [7, 12, 13], "limit": [7, 9, 14], "gpu": [7, 12, 14], "present": 7, "fullfil": 7, "pytorch": [8, 9, 13, 14], "librari": [8, 16], "host": [8, 11], "flexibl": [8, 16], "transform": [8, 13, 14, 16], "interoper": [8, 16], "build": [8, 9, 12, 15, 16], "state": [8, 16], "art": [8, 16], "api": [8, 15], "refer": [8, 13, 16], "replac": [8, 11, 14], "exist": [8, 11], "vit": [8, 11], "spars": [8, 9, 11], "blocksparseattent": [8, 11], "extend": [8, 11, 16], "zoo": [8, 11, 16], "interest": [8, 11], "here": [8, 9, 11], "triton": [8, 9, 11], "blockspars": 9, "tile": 9, "construct": [9, 10], "time": [9, 14], "simpl": 9, "just": [9, 13, 14], "minimum": 9, "being": [9, 14, 16], "coeffici": 9, "If": 9, "alreadi": [9, 13], "per": 9, "mind": [9, 13], "perfect": 9, "probabl": 9, "fine": [9, 15], "drop": [9, 14], "after": 9, "fact": 9, "grain": 9, "still": 9, "small": 9, "helper": [9, 12, 13, 15], "maxpool": 9, "binari": 9, "layout": 9, "pleas": [9, 12, 13], "now": [9, 10, 13], "requir": [9, 10, 12], "power": 9, "let": [9, 10, 13], "look": 9, "compon": [9, 10, 12, 13, 15], "multiheaddispatch": [9, 15], "seq": [9, 15], "2048": 9, "emb": 9, "1024": [9, 15], "block_siz": 9, "32": 9, "dropout": [9, 10, 15], "try": 9, "realli": [9, 16], "could": 9, "anyth": [9, 16], "causal_mask": 9, "tril": 9, "ones": 9, "causal_layout": 9, "_you": 9, "head_": 9, "commod": 9, "multihead": [9, 15], "multi_head": [9, 15], "respons": 9, "seq_len": [9, 15], "dim_model": [9, 15], "residual_dropout": [9, 15], "half": 9, "fw": [9, 12], "random": 9, "data": [9, 15], "remov": 9, "extra": [9, 10, 12, 13], "where": 9, "blockif": 9, "requires_grad": 9, "self": [9, 10, 12], "particular": [9, 13], "att_val": 9, "att_mask": [9, 13], "bonu": 9, "compar": [9, 12, 14, 16], "vs": 9, "def": [9, 10, 12, 13], "mem_us": 9, "fn": 9, "kwarg": [9, 10, 12], "titl": 9, "bookeep": 9, "empty_cach": 9, "reset_peak_memory_stat": 9, "run": [9, 14], "synchron": 9, "stop": 9, "report": 9, "max_memori": 9, "max_memory_alloc": 9, "20": 9, "f": [9, 12], "peak": 9, "mb": 9, "round": 9, "1e6": 9, "1e3": 9, "ms": 9, "pytorch_multihead": 9, "multiheadattent": 9, "batch_first": 9, "attn_mask": [9, 13], "On": 9, "v100": [9, 14], "9": 9, "someth": [9, 10, 12, 15], "line": [9, 14], "151mb": 9, "619m": 9, "393mb": 9, "837m": 9, "empti": 9, "more": [9, 10, 12, 13, 15, 16], "get": [9, 12, 13, 14], "bias": 9, "result": [9, 14], "toward": 9, "done": 10, "privat": 10, "fork": 10, "progress": 10, "share": 10, "point": [10, 14], "directli": [10, 14, 15], "order": 10, "submit": 10, "pr": [10, 16], "architectur": [10, 15, 16], "practic": [10, 13], "unit": [10, 14], "loos": 10, "inherit": 10, "expos": [10, 12, 13, 15], "exact": 10, "interfac": [10, 14], "consid": [10, 12, 13], "instanc": 10, "nystrom": 10, "dataclass": 10, "nystromselfattentionconfig": 10, "attentionconfig": 10, "register_attent": 10, "nystromattent": 10, "__init__": [10, 12], "float": 10, "num_landmark": 10, "64": 10, "landmark_pool": 10, "bool": [10, 12], "fals": [10, 12, 13, 14], "use_razavi_pinvers": 10, "pinverse_original_init": 10, "inv_iter": 10, "recommend": 10, "paper": [10, 12], "wa": [10, 12, 15], "v_skip_connect": 10, "conv_kernel_s": 10, "arg": 10, "remark": 10, "extens": [10, 16], "configur": 10, "explicitli": 10, "constructor": 10, "It": [10, 14], "benchmark": [10, 14, 16], "accept": 10, "even": 10, "field": [10, 16], "registr": 10, "snippet": 10, "ti": 10, "open": [10, 12], "up": [10, 12], "least": 10, "tool": 10, "toolbox": 10, "relev": [10, 16], "pick": 10, "variant": [10, 16], "call": 10, "them": [10, 12, 14], "go": 10, "pytest": 10, "my_component_nam": 10, "applic": [10, 12, 14], "lra": 10, "json": 10, "config": 10, "your": [10, 12, 15], "job": 10, "As": [10, 14], "remind": 10, "inform": 10, "dedic": 10, "readm": 10, "python3": [10, 14], "run_task": 10, "py": [10, 14], "task": 10, "config_path": 10, "world_siz": 10, "n": [10, 12], "slurm": 10, "cluster": 10, "batch_submit": 10, "c": 10, "checkpo": 10, "log": [10, 14], "path": [10, 12, 15], "residu": 12, "propos": [12, 13, 14, 16], "gomez": 12, "et": 12, "al": 12, "Its": 12, "context": 12, "reform": 12, "larg": 12, "unrel": 12, "lsh": 12, "chunk": 12, "mlp": 12, "process": 12, "lightli": 12, "adapt": 12, "robin": 12, "bruegger": 12, "lucidrain": 12, "x1": 12, "x2": 12, "produc": 12, "output": [12, 13], "y1": 12, "y2": 12, "g": 12, "turn": [12, 15], "mean": [12, 16], "recov": 12, "detail": 12, "anoth": 12, "effect": 12, "checkpoint": 12, "tradeoff": 12, "One": 12, "benefit": 12, "wrap": 12, "natur": 12, "distribut": 12, "free": 12, "help": 12, "save": 12, "commun": 12, "cost": 12, "moreov": 12, "stack": 12, "increas": [12, 14], "includ": 12, "norm": 12, "close": 12, "origin": 12, "formul": 12, "vaswani": 12, "deal": 12, "accuraci": 12, "affect": 12, "verifi": 12, "repositori": [12, 13], "main": 12, "reversibleblock": 12, "reversiblesequ": 12, "take": [12, 13, 15], "sequenti": 12, "similarli": 12, "modulelist": 12, "f_arg": 12, "g_arg": 12, "arg_rout": 12, "whether": [12, 15], "rout": 12, "boolean": 12, "complet": [12, 15], "factori": 12, "model_factori": 12, "yet": 12, "compat": [12, 14], "multipl": 12, "ddp": 12, "xformerstackconfig": 12, "block_config": 12, "xformerencoderconfig": 12, "xformerdecoderconfig": 12, "num_lay": 12, "ren": 12, "urtasun": 12, "gross": 12, "2017": 12, "network": 12, "backpropag": 12, "store": 12, "kitaev": 12, "kaiser": 12, "\u0142": 12, "levskaya": 12, "2020": 12, "sai": 13, "experi": 13, "show": 13, "how": [13, 14], "reus": [13, 16], "imag": 13, "aspect": 13, "translat": 13, "well": 13, "check": 13, "notebook": 13, "exhaust": 13, "timm": 13, "vision_transform": 13, "visiontransform": 13, "scaleddotproduct": 13, "timm_sparse_attent": 13, "timmsparseattent": 13, "img_siz": 13, "224": 13, "patch_siz": 13, "embed_dim": 13, "96": 13, "depth": 13, "mlp_ratio": 13, "qkv_bia": 13, "norm_lay": 13, "layernorm": 13, "suppos": 13, "snipper": 13, "precis": 13, "sever": 13, "attention_pattern": 13, "my_fancy_mask": 13, "recurs": 13, "monkei": 13, "patch": 13, "replace_attn_with_xformers_on": 13, "module_output": 13, "isinst": 13, "qkv": 13, "weight": 13, "minim": 13, "child": 13, "named_children": 13, "add_modul": 13, "del": 13, "awar": [13, 14], "variat": 13, "exchang": 13, "mai": 13, "good": 13, "idea": 13, "closer": 13, "typic": [13, 14], "exhibit": 13, "clear": 13, "sparsiti": 13, "alter": 13, "manual": 13, "sparsifi": 13, "languag": 14, "parallel": 14, "program": 14, "pure": 14, "mani": 14, "primit": 14, "tranform": 14, "backend": 14, "short": 14, "jit": 14, "toolchain": 14, "famili": 14, "consolid": 14, "hoc": 14, "over": 14, "avail": 14, "similar": [14, 15], "http": 14, "lang": 14, "org": 14, "02": 14, "html": 14, "sphx": 14, "glr": 14, "log_softmax": 14, "y": 14, "amp": 14, "autograd": 14, "expect": [14, 15], "throughput": 14, "nvidia": 14, "operand": 14, "relu": 14, "simpli": 14, "fusedlinear": 14, "my_linear_lay": 14, "in_featur": 14, "out_featur": 14, "squared_relu": 14, "skip": 14, "septemb": 14, "2021": 14, "faster": 14, "non": 14, "sigmoid": 14, "fp16": 14, "usecas": 14, "serv": 14, "measur": [14, 16], "laptop": 14, "3080": 14, "10": 14, "reproduc": 14, "benchmark_triton_layernorm": 14, "gb": 14, "benchmark_triton_dropout": 14, "own": 15, "everyth": 15, "depend": 15, "requires_head_dimens": 15, "flag": 15, "build_attent": 15, "dict": 15, "defer": 15, "lot": 15, "instanti": 15, "littl": 15, "obscur": 15, "although": 15, "hopefulli": 15, "straightforward": 15, "built": 15, "intern": 15, "sure": 15, "programat": 15, "sweep": 15, "search": [15, 16], "definit": 15, "384": 15, "my_config": 15, "attention_nam": 15, "easili": [15, 16], "attention_query_mask": 15, "rand": 15, "dummi": 15, "dispatch": 15, "my": 15, "focus": 16, "agnost": 16, "design": 16, "ideal": 16, "break": 16, "inspir": 16, "studi": 16, "ablat": 16, "aim": 16, "easi": 16, "focu": 16, "improv": 16, "against": 16, "across": 16, "domain": 16, "engin": 16, "effort": 16, "And": 16, "sinc": 16, "heavi": 16, "everi": 16, "repo": 16, "alon": 16, "happen": 16, "anytim": 16, "somebodi": 16, "through": 16, "crowd": 16, "welcom": 16, "move": 16, "too": 16}, "objects": {"xformers.ops.fmha": [[4, 0, 0, "-", "attn_bias"], [4, 0, 0, "-", "ck"], [4, 0, 0, "-", "ck_decoder"], [4, 0, 0, "-", "ck_splitk"]], "xformers.ops.fmha.attn_bias": [[4, 1, 1, "", "AttentionBias"], [4, 1, 1, "", "BlockDiagonalCausalFromBottomRightMask"], [4, 1, 1, "", "BlockDiagonalCausalLocalAttentionFromBottomRightMask"], [4, 1, 1, "", "BlockDiagonalCausalLocalAttentionMask"], [4, 1, 1, "", "BlockDiagonalCausalMask"], [4, 1, 1, "", "BlockDiagonalCausalWithOffsetGappyKeysMask"], [4, 1, 1, "", "BlockDiagonalCausalWithOffsetPaddedKeysMask"], [4, 1, 1, "", "BlockDiagonalGappyKeysMask"], [4, 1, 1, "", "BlockDiagonalMask"], [4, 1, 1, "", "BlockDiagonalPaddedKeysMask"], [4, 1, 1, "", "LocalAttentionFromBottomRightMask"], [4, 1, 1, "", "LowerTriangularFromBottomRightLocalAttentionMask"], [4, 1, 1, "", "LowerTriangularFromBottomRightMask"], [4, 1, 1, "", "LowerTriangularMask"], [4, 1, 1, "", "LowerTriangularMaskWithTensorBias"], [4, 1, 1, "", "PagedBlockDiagonalCausalWithOffsetPaddedKeysMask"], [4, 1, 1, "", "PagedBlockDiagonalGappyKeysMask"], [4, 1, 1, "", "PagedBlockDiagonalPaddedKeysMask"]], "xformers.ops.fmha.attn_bias.AttentionBias": [[4, 2, 1, "", "materialize"]], "xformers.ops.fmha.attn_bias.BlockDiagonalCausalWithOffsetGappyKeysMask": [[4, 2, 1, "", "materialize"]], "xformers.ops.fmha.attn_bias.BlockDiagonalCausalWithOffsetPaddedKeysMask": [[4, 2, 1, "", "from_seqlens"]], "xformers.ops.fmha.attn_bias.BlockDiagonalGappyKeysMask": [[4, 2, 1, "", "from_seqlens"], [4, 2, 1, "", "make_paged"], [4, 2, 1, "", "materialize"]], "xformers.ops.fmha.attn_bias.BlockDiagonalMask": [[4, 2, 1, "", "from_seqlens"], [4, 2, 1, "", "from_tensor_list"], [4, 2, 1, "", "make_causal"], [4, 2, 1, "", "make_causal_from_bottomright"], [4, 2, 1, "", "make_local_attention"], [4, 2, 1, "", "make_local_attention_from_bottomright"], [4, 2, 1, "", "materialize"], [4, 2, 1, "", "split"]], "xformers.ops.fmha.attn_bias.BlockDiagonalPaddedKeysMask": [[4, 2, 1, "", "from_seqlens"], [4, 2, 1, "", "materialize"]], "xformers.ops.fmha.attn_bias.LowerTriangularFromBottomRightMask": [[4, 2, 1, "", "make_local_attention"]], "xformers.ops.fmha.attn_bias.LowerTriangularMask": [[4, 2, 1, "", "add_bias"]], "xformers.ops.fmha.attn_bias.PagedBlockDiagonalGappyKeysMask": [[4, 2, 1, "", "from_seqlens"], [4, 2, 1, "", "materialize"]], "xformers.ops.fmha.attn_bias.PagedBlockDiagonalPaddedKeysMask": [[4, 2, 1, "", "from_seqlens"], [4, 2, 1, "", "materialize"]], "xformers.ops.fmha.ck": [[4, 1, 1, "", "BwOp"], [4, 1, 1, "", "FwOp"]], "xformers.ops.fmha.ck_decoder": [[4, 1, 1, "", "FwOp"]], "xformers": [[7, 0, 0, "-", "triton"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"attent": [0, 3, 4, 13, 15], "mechan": [0, 1, 15], "feedforward": 1, "api": 2, "refer": [2, 7], "multi": 3, "head": 3, "xformer": [4, 8, 10, 16], "optim": 4, "oper": 4, "memori": 4, "effici": 4, "avail": 4, "implement": 4, "bias": 4, "non": 4, "autograd": 4, "posit": 5, "embed": 5, "revers": [6, 12], "layer": [6, 14], "custom": [7, 8], "part": [7, 8, 10], "spars": [7, 13], "cuda": 7, "kernel": 7, "1": 7, "build": 7, "2": 7, "usag": 7, "triton": [7, 14], "requir": 7, "possibl": 7, "welcom": 8, "s": 8, "document": 8, "compon": 8, "tutori": [8, 11], "exampl": 8, "some": 8, "us": [9, 12, 14], "blocksparseattent": 9, "extend": 10, "zoo": 10, "block": 12, "intro": 12, "transform": 12, "In": 12, "practic": 12, "replac": 13, "all": 13, "from": 13, "an": 13, "exist": 13, "vit": 13, "model": 13, "equival": 13, "base": 14, "fuse": 14, "softmax": 14, "linear": 14, "norm": 14, "dropout": 14, "bia": 14, "activ": 14, "i": 15, "m": 15, "onli": 15, "interest": 15, "test": 15, "out": 15, "ar": 15, "host": 15, "here": 15, "what": 16}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})